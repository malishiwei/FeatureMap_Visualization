{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\"> Inception-v3 <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code are based on the article https://distill.pub/2017/feature-visualization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import transfer_learning_v3 # This module is from homework4 and we just made several changes to the return values of _create_model() \n",
    "import pandas as pd\n",
    "from scipy.misc import imsave\n",
    "from scipy.stats import rankdata\n",
    "import time\n",
    "import fnmatch\n",
    "from PIL import Image\n",
    "from math import ceil, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parser tensor from pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_tensor(layer_name,model_dir):\n",
    "    \"\"\"input: the output of layer you want\"\"\"\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        model_path=os.path.join(model_dir,\"classify_image_graph_def.pb\")\n",
    "        with tf.gfile.FastGFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_model_graph() -> typing.Tuple[tf.Graph, tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"\"Creates a graph from saved GraphDef file and returns a Graph object.\n",
    "\n",
    "    This creates the graph for the Inception model that was downloaded.\n",
    "\n",
    "    Returns:\n",
    "      Graph holding the trained Inception network, and various tensors we'll be\n",
    "      manipulating.\n",
    "    \"\"\"\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        model_path = os.path.join(_MODEL_DIR, 'classify_image_graph_def.pb')\n",
    "        with tf.gfile.FastGFile(model_path, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            bottleneck, resized_input, softmax,conv,conv1,conv2,pool,conv3,conv4,pool1,conv_W,conv1_W,conv2_W,conv3_W,conv4_W= (tf.import_graph_def(\n",
    "                graph_def,\n",
    "                name='',\n",
    "                return_elements=[\n",
    "                    'pool_3/_reshape:0',  # bottleneck tensor name\n",
    "                    'Mul:0',  # resized input tensor name\n",
    "                    'softmax:0',  # predicted probability tensor name\n",
    "                    \"conv:0\",\n",
    "                    \"conv_1:0\",\n",
    "                    \"conv_2:0\",\n",
    "                    'pool:0',\n",
    "                    \"conv_3:0\",\n",
    "                    \"conv_4:0\",\n",
    "                    'pool_1:0',\n",
    "                    \"conv/conv2d_params:0\",\n",
    "                    \"conv_1/conv2d_params:0\",\n",
    "                    \"conv_2/conv2d_params:0\",\n",
    "                    \"conv_3/conv2d_params:0\",\n",
    "                    \"conv_4/conv2d_params:0\",\n",
    "                ]))\n",
    "    return graph, bottleneck, resized_input, softmax,conv,conv1,conv2,pool,conv3,conv4,pool1,conv_W,conv1_W,conv2_W,conv3_W,conv4_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Channel: Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deepdream(graph, sess, op_tensor, X, feed_dict, layer, path_outdir, path_logdir):\n",
    "    tensor_shape = op_tensor.get_shape().as_list()\n",
    "\n",
    "    with graph.as_default() as g:\n",
    "        n = (config[\"N\"] + 1) // 2\n",
    "        feature_map = tf.placeholder(dtype = tf.int32)\n",
    "        tmp1 = tf.reduce_mean(tf.multiply(tf.gather(tf.transpose(op_tensor),feature_map),tf.diag(tf.ones_like(feature_map, dtype = tf.float32))), axis = 0)\n",
    "        tmp2 = 1e-3 * tf.reduce_mean(tf.square(X), axis = (1, 2 ,3))\n",
    "        tmp = tmp1 - tmp2\n",
    "        t_grad = tf.gradients(ys = tmp, xs = X)[0]\n",
    "\n",
    "        with sess.as_default() as sess:\n",
    "            input_shape = sess.run(tf.shape(X), feed_dict = feed_dict)\n",
    "            tile_size = input_shape[1 : 3]\n",
    "            channels = input_shape[3]\n",
    "\n",
    "            lap_in = tf.placeholder(np.float32, name='lap_in')\n",
    "            laplacian_pyramid = lap_normalize(lap_in, channels, scale_n=config[\"NUM_LAPLACIAN_LEVEL\"])\n",
    "\n",
    "            image_to_resize = tf.placeholder(np.float32, name='image_to_resize')\n",
    "            size_to_resize = tf.placeholder(np.int32, name='size_to_resize')\n",
    "            resize_image = tf.image.resize_bilinear(image_to_resize, size_to_resize)\n",
    "\n",
    "            end = len(units)\n",
    "            for k in range(0, end, n):\n",
    "                c = n\n",
    "                if k + n > end:\n",
    "                    c = end - ((end // n) * n)\n",
    "                img = np.random.uniform(size = (c, tile_size[0], tile_size[1], channels)) + 117.0\n",
    "                feed_dict[feature_map] = units[k : k + c]\n",
    "\n",
    "                for octave in range(config[\"NUM_OCTAVE\"]):\n",
    "                    if octave > 0:\n",
    "                        hw = np.float32(img.shape[1:3])*config[\"OCTAVE_SCALE\"]\n",
    "                        img = sess.run(resize_image, {image_to_resize : img, size_to_resize : np.int32(hw)})\n",
    "\n",
    "                        for i, im in enumerate(img):\n",
    "                            min_img = im.min()\n",
    "                            max_img = im.max()\n",
    "                            temp = denoise_tv_bregman((im - min_img) / (max_img - min_img), weight = config[\"TV_DENOISE_WEIGHT\"])\n",
    "                            img[i] = (temp * (max_img - min_img) + min_img).reshape(img[i].shape)\n",
    "\n",
    "                    for j in range(config[\"NUM_ITERATION\"]):\n",
    "                        sz = tile_size\n",
    "                        h, w = img.shape[1:3]\n",
    "                        sx = np.random.randint(sz[1], size=1)\n",
    "                        sy = np.random.randint(sz[0], size=1)\n",
    "                        img_shift = np.roll(np.roll(img, sx, 2), sy, 1)\n",
    "                        grad = np.zeros_like(img)\n",
    "                        for y in range(0, max(h-sz[0]//2,sz[0]), sz[0] // 2):\n",
    "                            for x in range(0, max(h-sz[1]//2,sz[1]), sz[1] // 2):\n",
    "                                    feed_dict[X] = img_shift[:, y:y+sz[0],x:x+sz[1]]\n",
    "                                    try:\n",
    "                                        grad[:, y:y+sz[0],x:x+sz[1]] = sess.run(t_grad, feed_dict=feed_dict)\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                        lap_out = sess.run(laplacian_pyramid, feed_dict={lap_in:np.roll(np.roll(grad, -sx, 2), -sy, 1)})\n",
    "                        img = img + lap_out\n",
    "                is_success = write_results(img, (layer, units, k), path_outdir, path_logdir, method = \"deepdream\")\n",
    "                print(\"%s -> featuremap completed.\" % (\", \".join(str(num) for num in units[k:k+c])))\n",
    "    return is_success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Class Logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Class probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
