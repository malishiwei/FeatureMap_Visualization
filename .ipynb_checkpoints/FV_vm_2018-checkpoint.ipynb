{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "464d1a9b-a959-4f0a-ba4c-cdbcc2012734"
    }
   },
   "source": [
    "# <font color=\"green\"> GAN:inverse feature map back to images <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e988d9b3-6db8-4109-976a-1907e4808cee"
    }
   },
   "source": [
    "This code are based on the article https://distill.pub/2017/feature-visualization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "7956fd61-1839-4764-9559-376fa836ab37"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "#import transfer_learning_v3 # This module is from homework4 and we just made several changes to the return values of _create_model() \n",
    "import pandas as pd\n",
    "from scipy.misc import imsave\n",
    "from scipy.stats import rankdata\n",
    "import time\n",
    "import fnmatch\n",
    "from PIL import Image\n",
    "from math import ceil, sqrt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "bf817c01-e8ea-4690-b990-f2ff42d7576f"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image paths of our dataset\n",
    "images = ['*.JPG', '*.JPEG', '*.png', '*.tif', '*.tiff']\n",
    "image_path = []\n",
    "for root,dirnames, filenames in os.walk(\"/home/fancymali666/FV/ILSVRC2010_images_val\"):\n",
    "    for extension in images:\n",
    "        for filename in fnmatch.filter(filenames, extension):\n",
    "            image_path.append(os.path.join(root, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tensor(layer_name):\n",
    "    \"\"\"input: the output of layer you want\"\"\"\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        model_path=os.path.join(\"./model\",\"classify_image_graph_def.pb\")\n",
    "        with tf.gfile.FastGFile(model_path,\"rb\") as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tensors=tf.import_graph_def(graph_def,name=\"\",return_elements=layer_name)\n",
    "            return graph,tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(path,val_ratio):\n",
    "    start_time = time.time()\n",
    "    Graph,tensors=fetch_tensor([\"Mul:0\",\"softmax:0\"])\n",
    "    image_list=[]\n",
    "    logits_list=[]\n",
    "    for i in range(len(path)):\n",
    "        image_path = path[i]\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image_data=f.read()\n",
    "        with tf.Session(graph=Graph,config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "            image_list.append(session.run(tensors[0],feed_dict={\"DecodeJpeg/contents:0\":image_data}))\n",
    "            logits_list.append(session.run(tensors[1],feed_dict={\"DecodeJpeg/contents:0\":image_data}))\n",
    "            if i%50==0:\n",
    "                print(\"loading image:\"+str(i)+\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    train_image,val_image = train_test_split(image_list,test_size=val_ratio,random_state=0)\n",
    "    train_logits,val_logits = train_test_split(logits_list,test_size=val_ratio,random_state=0)\n",
    "    train_image_reshaped = np.stack(train_image).reshape(-1,299,299,3)\n",
    "    val_image_reshaped = np.stack(val_image).reshape(-1,299,299,3)\n",
    "    train_logits_reshaped = np.stack(train_logits).reshape(-1,1008)\n",
    "    val_logits_reshaped = np.stack(val_logits).reshape(-1,1008)\n",
    "    \n",
    "    return train_image_reshaped,train_logits_reshaped,val_image_reshaped,val_logits_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d64269f0-dccc-4fb9-8740-96b03389c9b9"
    }
   },
   "source": [
    "### Part1. Build the generator G and Distinguisher D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-defined functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "5f1deeb4-e8d2-4d01-8f21-afc298bae52a"
    }
   },
   "outputs": [],
   "source": [
    "def batch_normalization(xs,N):\n",
    "    mean=tf.Variable(tf.random_normal(mean=0, stddev=0.02,shape=[N]),dtype=tf.float32)\n",
    "    var=tf.Variable(tf.random_uniform(minval=0, maxval=None,shape=[N]),dtype=tf.float32)\n",
    "    g=tf.Variable(tf.ones(shape=[N]),dtype=tf.float32)\n",
    "    b=tf.Variable(tf.random_normal(mean=0, stddev=0.2,shape=[N]),dtype=tf.float32)\n",
    "    out = tf.nn.batch_norm_with_global_normalization(xs,m=mean,v=var,beta=b,gamma=g,variance_epsilon=0.001,scale_after_normalization=False)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "6777bc6a-24b5-474f-aeab-946d555d0f2b"
    }
   },
   "outputs": [],
   "source": [
    "def tf_normalize(x):\n",
    "    abs_max=tf.reduce_max(tf.abs(x),axis=[0,1,2,3],keep_dims=True)\n",
    "    out=tf.div(x,abs_max)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "02b9c153-6938-48e7-8bc4-31f16c0640ef"
    }
   },
   "source": [
    "### 1. Comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "a230ec06-158d-432f-8ad6-53149ba75ca6"
    }
   },
   "outputs": [],
   "source": [
    "conv_W_name=[\"conv/conv2d_params:0\",\"conv_1/conv2d_params:0\",\"conv_2/conv2d_params:0\",\"conv_3/conv2d_params:0\",\"conv_4/conv2d_params:0\"]\n",
    "conv_beta_name=[\"conv/batchnorm/beta:0\",\"conv_1/batchnorm/beta:0\",\"conv_2/batchnorm/beta:0\",\"conv_3/batchnorm/beta:0\"\n",
    "                  ,\"conv_4/batchnorm/beta:0\"]\n",
    "conv_var_name=[\"conv/batchnorm/moving_variance:0\",\"conv_1/batchnorm/moving_variance:0\",\"conv_2/batchnorm/moving_variance:0\"\n",
    "                 ,\"conv_3/batchnorm/moving_variance:0\",\"conv_4/batchnorm/moving_variance:0\"]\n",
    "conv_mean_name=[\"conv/batchnorm/moving_mean:0\",\"conv_1/batchnorm/moving_mean:0\",\"conv_2/batchnorm/moving_mean:0\"\n",
    "                  ,\"conv_3/batchnorm/moving_mean:0\", \"conv_4/batchnorm/moving_mean:0\"]\n",
    "conv_gamma_name=[\"conv/batchnorm/gamma:0\",\"conv_1/batchnorm/gamma:0\",\"conv_2/batchnorm/gamma:0\",\"conv_3/batchnorm/gamma:0\"\n",
    "                   ,\"conv_4/batchnorm/gamma:0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "b25098ee-0cd9-4949-95a4-bc523e1b23a1"
    }
   },
   "outputs": [],
   "source": [
    "graph_W,conv_W_tensor=fetch_tensor(conv_W_name)\n",
    "graph_beta,conv_beta_tensor=fetch_tensor(conv_beta_name)\n",
    "graph_var,conv_var_tensor=fetch_tensor(conv_var_name)\n",
    "graph_mean,conv_mean_tensor=fetch_tensor(conv_mean_name)\n",
    "graph_gamma,conv_gamma_tensor=fetch_tensor(conv_gamma_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image:0--- 1.1792144775390625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "sample_image=generate_dataset(image_path[0:5],0.2)[0][0:1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbpresent": {
     "id": "688a6e40-43ce-4f82-a835-3ab02d487fa8"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph_W) as session:\n",
    "    conv_W=[i.eval(feed_dict={\"Mul:0\":sample_image}) for i in conv_W_tensor]\n",
    "with tf.Session(graph=graph_beta) as session:\n",
    "    conv_beta=[i.eval(feed_dict={\"Mul:0\":sample_image}) for i in conv_beta_tensor]\n",
    "with tf.Session(graph=graph_var) as session:\n",
    "    conv_var=[i.eval(feed_dict={\"Mul:0\":sample_image}) for i in conv_var_tensor]\n",
    "with tf.Session(graph=graph_mean) as session:\n",
    "    conv_mean=[i.eval(feed_dict={\"Mul:0\":sample_image}) for i in conv_mean_tensor]\n",
    "with tf.Session(graph=graph_gamma) as session:\n",
    "    conv_gamma=[i.eval(feed_dict={\"Mul:0\":sample_image}) for i in conv_gamma_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbpresent": {
     "id": "602d716f-7635-48b8-b000-0fd9cac030d9"
    }
   },
   "outputs": [],
   "source": [
    "def Comparator_features(x):\n",
    "    \n",
    "    with tf.name_scope(\"Comparator\"):\n",
    "         # layer cnn1\n",
    "        with tf.variable_scope('conv') as scope: \n",
    "            Wx_conv= tf.nn.conv2d(x, filter=conv_W[0], strides=[1, 2, 2, 1], padding='VALID')  \n",
    "            batchnorm_conv=tf.nn.batch_norm_with_global_normalization(Wx_conv,m=conv_mean[0],v=conv_var[0],beta=conv_beta[0]\n",
    "                                                ,gamma=conv_gamma[0], variance_epsilon=0.001,scale_after_normalization=False)\n",
    "            conv_output=tf.nn.relu(batchnorm_conv)  \n",
    "\n",
    "        # layer cnn2\n",
    "        with tf.variable_scope('conv1') as scope: \n",
    "            Wx_conv1 = tf.nn.conv2d(conv_output, filter=conv_W[1], strides=[1, 1, 1, 1], padding='VALID')  \n",
    "            batchnorm_conv1=tf.nn.batch_norm_with_global_normalization(Wx_conv1,m=conv_mean[1],v=conv_var[1],beta=conv_beta[1]\n",
    "                                                ,gamma=conv_gamma[1], variance_epsilon=0.001,scale_after_normalization=False)\n",
    "            conv1_output=tf.nn.relu(batchnorm_conv1)  \n",
    "\n",
    "        # layer cnn3\n",
    "        with tf.variable_scope('conv2') as scope: \n",
    "            Wx_conv2 = tf.nn.conv2d(conv1_output, filter=conv_W[2], strides=[1, 1, 1, 1], padding='SAME')  \n",
    "            batchnorm_conv2=tf.nn.batch_norm_with_global_normalization(Wx_conv2,m=conv_mean[2],v=conv_var[2],beta=conv_beta[2]\n",
    "                                                ,gamma=conv_gamma[2], variance_epsilon=0.001,scale_after_normalization=False)\n",
    "            conv2_output=tf.nn.relu(batchnorm_conv2)  \n",
    "\n",
    "        # layer pool\n",
    "        with tf.variable_scope('pool') as scope: \n",
    "            pool_output = tf.nn.max_pool(conv2_output,ksize=[1,3,3,1],strides=[1,2,2,1],padding=\"VALID\")\n",
    "\n",
    "        # layer cnn3\n",
    "        with tf.variable_scope('conv3') as scope: \n",
    "            Wx_conv3 = tf.nn.conv2d(pool_output, filter=conv_W[3], strides=[1, 1, 1, 1], padding='VALID')  \n",
    "            batchnorm_conv3=tf.nn.batch_norm_with_global_normalization(Wx_conv3,m=conv_mean[3],v=conv_var[3],beta=conv_beta[3]\n",
    "                                                ,gamma=conv_gamma[3], variance_epsilon=0.001,scale_after_normalization=False)\n",
    "            conv3_output=tf.nn.relu(batchnorm_conv3)  \n",
    "\n",
    "        # layer cnn4\n",
    "        with tf.variable_scope('conv4') as scope: \n",
    "            Wx_conv4 = tf.nn.conv2d(conv3_output, filter=conv_W[4], strides=[1, 1, 1, 1], padding='VALID')  \n",
    "            batchnorm_conv4=tf.nn.batch_norm_with_global_normalization(Wx_conv4,m=conv_mean[4],v=conv_var[4],beta=conv_beta[4]\n",
    "                                                ,gamma=conv_gamma[4], variance_epsilon=0.001,scale_after_normalization=False)\n",
    "            conv4_output=tf.nn.relu(batchnorm_conv4)  \n",
    "\n",
    "        # layer pool_1\n",
    "        with tf.variable_scope('pool_1') as scope: \n",
    "            pool1_output = tf.nn.max_pool(conv4_output,ksize=[1,3,3,1],strides=[1,2,2,1],padding=\"VALID\")\n",
    "\n",
    "    return conv_output,conv2_output,conv4_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ffd261c4-3e5f-4e0c-be7c-23b9107b5f48"
    }
   },
   "source": [
    "### 2. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbpresent": {
     "id": "86999195-0106-4e5b-a367-eb05c85e4c71"
    }
   },
   "outputs": [],
   "source": [
    "def Generator_image(input_feature,batch_size):\n",
    "    \n",
    "    with tf.name_scope(\"Generator_Network\"):\n",
    "        tf.set_random_seed(0)\n",
    "        # fc1: logits\n",
    "        with tf.variable_scope('fc1') as scope: \n",
    "            \n",
    "            W_fc1 = tf.get_variable('W_fc1', shape=[1008, 2048],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                    ,dtype=tf.float32)\n",
    "            b_fc1 = tf.get_variable('b_fc1', shape=[2048],initializer=tf.random_normal_initializer(mean=0, stddev=0.02),dtype=tf.float32)\n",
    "            fc1_Wx_b = tf.nn.relu(tf.add(tf.matmul(input_feature, W_fc1), b_fc1))\n",
    "            fc1_output = tf.nn.l2_normalize(fc1_Wx_b,dim=1,name=\"fc1_output\")\n",
    "\n",
    "            \n",
    "        # unconv\n",
    "        with tf.variable_scope('unconv') as scope:\n",
    "            unconv_reshape = tf.reshape(fc1_output,shape=[batch_size,1,1,2048])\n",
    "            unconv_W = tf.get_variable('unconv_W', shape=[3,3,2048, 2048],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu = tf.nn.relu(unconv_reshape)\n",
    "            unBias = unReLu\n",
    "            batchnorm_unconv=batch_normalization(unBias,2048)\n",
    "            unConv = tf.nn.conv2d_transpose(batchnorm_unconv,unconv_W, output_shape=[batch_size,3,3,2048] , strides=[1,2,2,1]\n",
    "                                              , padding=\"VALID\")\n",
    "        \n",
    "    \n",
    "        # unconv1: pool_3\n",
    "        with tf.variable_scope('unconv1') as scope:\n",
    "            unconv1_W = tf.get_variable('unconv1_W', shape=[2,2,2048, 2048],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_1 = tf.nn.relu(unConv)\n",
    "            unBias_1 = unReLu_1\n",
    "            batchnorm_unconv1=batch_normalization(unBias_1,2048)\n",
    "            unConv_1 = tf.nn.conv2d_transpose(batchnorm_unconv1,unconv1_W, output_shape=[batch_size,8,8,2048] , strides=[1,3,3,1]\n",
    "                                              , padding=\"VALID\")\n",
    "\n",
    "\n",
    "        #unconv2: mixed_10\n",
    "        with tf.variable_scope('unconv2') as scope:\n",
    "            unconv2_W = tf.get_variable('unconv2_W', shape=[3,3,1280,2048],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_2 = tf.nn.relu(unConv_1)\n",
    "            unBias_2 = unReLu_2\n",
    "            batchnorm_unconv2=batch_normalization(unBias_2,2048)\n",
    "            unConv_2 = tf.nn.conv2d_transpose(batchnorm_unconv2,unconv2_W, output_shape=[batch_size,8,8,1280] , strides=[1,1,1,1]\n",
    "                                              , padding=\"SAME\")\n",
    "\n",
    "\n",
    "        #unconv3: mixed_8\n",
    "        with tf.variable_scope('unconv3') as scope:\n",
    "            unconv3_W = tf.get_variable('unconv3_W', shape=[3,3,768,1280],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_3 = tf.nn.relu(unConv_2)\n",
    "            unBias_3 = unReLu_3\n",
    "            batchnorm_unconv3=batch_normalization(unBias_3,1280)\n",
    "            unConv_3 = tf.nn.conv2d_transpose(batchnorm_unconv3,unconv3_W, output_shape=[batch_size,17,17,768] , strides=[1,2,2,1]\n",
    "                                              , padding=\"VALID\")\n",
    "\n",
    "\n",
    "        #unconv4: mixed_3\n",
    "        with tf.variable_scope('unconv4') as scope:\n",
    "            unconv4_W = tf.get_variable('unconv4_W', shape=[3,3,288,768],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_4 = tf.nn.relu(unConv_3)\n",
    "            unBias_4 = unReLu_4\n",
    "            batchnorm_unconv4=batch_normalization(unBias_4,768)\n",
    "            unConv_4 = tf.nn.conv2d_transpose(batchnorm_unconv4,unconv4_W, output_shape=[batch_size,35,35,288] , strides=[1,2,2,1]\n",
    "                                              , padding=\"VALID\")\n",
    "\n",
    "\n",
    "        #unconv5: mixed_1\n",
    "        with tf.variable_scope('unconv5') as scope:\n",
    "            unconv5_W = tf.get_variable('unconv5_W', shape=[4,4,256,288],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_5 = tf.nn.relu(unConv_4)\n",
    "            unBias_5 = unReLu_5\n",
    "            batchnorm_unconv5=batch_normalization(unBias_5,288)\n",
    "            unConv_5 = tf.nn.conv2d_transpose(batchnorm_unconv5,unconv5_W, output_shape=[batch_size,35,35,256] , strides=[1,1,1,1]\n",
    "                                              , padding=\"SAME\")\n",
    "\n",
    "\n",
    "        #unconv6: mixed\n",
    "        with tf.variable_scope('unconv6') as scope:\n",
    "            unconv6_W = tf.get_variable('unconv6_W', shape=[4,4,192,256],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_6 = tf.nn.relu(unConv_5)\n",
    "            unBias_6 = unReLu_6\n",
    "            batchnorm_unconv6=batch_normalization(unBias_6,256)\n",
    "            unConv_6 = tf.nn.conv2d_transpose(batchnorm_unconv6,unconv6_W, output_shape=[batch_size,35,35,192] , strides=[1,1,1,1]\n",
    "                                              , padding=\"SAME\")\n",
    "\n",
    "\n",
    "        #unconv7: pool_1\n",
    "        with tf.variable_scope('unconv7') as scope:\n",
    "            unconv7_W = tf.get_variable('unconv7_W', shape=[3,3,192,192],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_7 = tf.nn.relu(unConv_6)\n",
    "            unBias_7 = unReLu_7\n",
    "            batchnorm_unconv7=batch_normalization(unBias_7,192)\n",
    "            unConv_7 = tf.nn.conv2d_transpose(batchnorm_unconv7,unconv7_W, output_shape=[batch_size,71,71,192] , strides=[1,2,2,1]\n",
    "                                              , padding=\"VALID\")\n",
    "\n",
    "\n",
    "        #unconv8: conv4\n",
    "        with tf.variable_scope('unconv8') as scope:\n",
    "            unconv8_W = tf.get_variable('unconv8_W', shape=[3,3,80,192],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_8 = tf.nn.relu(unConv_7)\n",
    "            unBias_8 = unReLu_8\n",
    "            batchnorm_unconv8=batch_normalization(unBias_8,192)\n",
    "            unConv_8= tf.nn.conv2d_transpose(batchnorm_unconv8,unconv8_W, output_shape=[batch_size,73,73,80] , strides=[1,1,1,1], padding=\"VALID\")\n",
    "\n",
    "\n",
    "        #unconv9: conv3\n",
    "        with tf.variable_scope('unconv9') as scope:\n",
    "            unconv9_W = tf.get_variable('unconv9_W', shape=[4,4,64,80],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_9 = tf.nn.relu(unConv_8)\n",
    "            unBias_9 = unReLu_9\n",
    "            batchnorm_unconv9=batch_normalization(unBias_9,80)\n",
    "            unConv_9= tf.nn.conv2d_transpose(batchnorm_unconv9,unconv9_W, output_shape=[batch_size,73,73,64] , strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "        #unconv10: pool\n",
    "        with tf.variable_scope('unconv10') as scope:\n",
    "            unconv10_W = tf.get_variable('unconv10_W', shape=[3,3,64,64],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_10 = tf.nn.relu(unConv_9)\n",
    "            unBias_10 = unReLu_10\n",
    "            batchnorm_unconv10=batch_normalization(unBias_10,64)\n",
    "            unConv_10= tf.nn.conv2d_transpose(batchnorm_unconv10,unconv10_W, output_shape=[batch_size,147,147,64] , strides=[1,2,2,1]\n",
    "                                              , padding=\"VALID\")\n",
    "\n",
    "\n",
    "        #unconv11: conv2\n",
    "        with tf.variable_scope('unconv11') as scope:\n",
    "            unconv11_W = tf.get_variable('unconv11_W', shape=[3,3,32,64],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_11 = tf.nn.relu(unConv_10)\n",
    "            unBias_11 = unReLu_11\n",
    "            batchnorm_unconv11=batch_normalization(unBias_11,64)\n",
    "            unConv_11= tf.nn.conv2d_transpose(batchnorm_unconv11,unconv11_W, output_shape=[batch_size,147,147,32] , strides=[1,1,1,1]\n",
    "                                              , padding=\"SAME\")\n",
    "\n",
    "\n",
    "        #unconv12: conv1\n",
    "        with tf.variable_scope('unconv12') as scope:\n",
    "            unconv12_W = tf.get_variable('unconv12_W', shape=[3,3,32,32],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unReLu_12 = tf.nn.relu(unConv_11)\n",
    "            unBias_12 = unReLu_12\n",
    "            batchnorm_unconv12=batch_normalization(unBias_12,32)\n",
    "            unConv_12= tf.nn.conv2d_transpose(batchnorm_unconv12,unconv12_W, output_shape=[batch_size,149,149,32] , strides=[1,1,1,1]\n",
    "                                              , padding=\"VALID\")\n",
    "\n",
    "\n",
    "        #unconv13: conv\n",
    "        with tf.variable_scope('unconv13') as scope:\n",
    "            unconv13_W = tf.get_variable('unconv13_W', shape=[3,3,3,32],initializer=tf.random_normal_initializer(mean=0, stddev=0.02)\n",
    "                                        ,dtype=tf.float32)\n",
    "            unTanh_13 = tf.nn.tanh(unConv_12)\n",
    "            unBias_13 = unTanh_13\n",
    "            batchnorm_unconv13=batch_normalization(unBias_13,32)\n",
    "            unConv_13= tf.nn.conv2d_transpose(batchnorm_unconv13,unconv13_W, output_shape=[batch_size,299,299,3] , strides=[1,2,2,1]\n",
    "                                              , padding=\"VALID\")\n",
    "        with tf.name_scope(\"output_image\"):\n",
    "            output_image = tf_normalize(unConv_13)\n",
    "            \n",
    "    # the outpu_image is fake image inverted from a feature map with shape = [None,299,299,3]\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3be4e515-4321-43b8-8cd7-8ae025918d55"
    }
   },
   "source": [
    "### 3. Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbpresent": {
     "id": "f69bdf7b-834b-4f0b-912f-a4cf1d836f4e"
    }
   },
   "outputs": [],
   "source": [
    "def Discriminator_probs(x,pkeep):\n",
    "    tf.set_random_seed(0)\n",
    "    with tf.name_scope('Discriminator'):\n",
    "        # layer cnn1\n",
    "        with tf.variable_scope('conv1') as scope: \n",
    "            W_conv1 = tf.get_variable('W_conv1', shape=[7,7,3,32])    \n",
    "            Wx_conv1 = tf.nn.conv2d(x, filter=W_conv1, strides=[1, 2, 2, 1], padding='SAME')  \n",
    "            b_conv1 = tf.get_variable('b_conv1', shape=[32])\n",
    "            Wx_plus_b_conv1 = tf.nn.bias_add(Wx_conv1, b_conv1,name=\"Wx_plus_b1\")\n",
    "            batchnorm_conv1 = batch_normalization(Wx_plus_b_conv1,32)\n",
    "            conv1_output=tf.nn.leaky_relu(batchnorm_conv1,alpha=0.3,name=\"relu1\")  \n",
    "\n",
    "        # layer cnn2\n",
    "        with tf.variable_scope('conv2') as scope: \n",
    "            W_conv2 = tf.get_variable('W_conv2', shape=[5,5,32,64])    \n",
    "            Wx_conv2 = tf.nn.conv2d(conv1_output, filter=W_conv2,strides=[1, 2, 2, 1], padding='SAME')  \n",
    "            b_conv2 = tf.get_variable('b_conv2', shape=[64])\n",
    "            Wx_plus_b_conv2 = tf.nn.bias_add(Wx_conv2, b_conv2,name=\"Wx_plus_b2\")  \n",
    "            batchnorm_conv2 = batch_normalization(Wx_plus_b_conv2,64)\n",
    "            conv2_output=tf.nn.leaky_relu(batchnorm_conv2,alpha=0.3,name=\"relu2\")  \n",
    "\n",
    "        # layer cnn3\n",
    "        with tf.variable_scope('conv3') as scope: \n",
    "            W_conv3 = tf.get_variable('W_conv3', shape=[3,3,64,128])    \n",
    "            Wx_conv3 = tf.nn.conv2d(conv2_output, filter=W_conv3,strides=[1, 2, 2, 1], padding='SAME')  \n",
    "            b_conv3 = tf.get_variable('b_conv3', shape=[128])\n",
    "            Wx_plus_b_conv3 = tf.nn.bias_add(Wx_conv3, b_conv3,name=\"Wx_plus_b3\")  \n",
    "            batchnorm_conv3 = batch_normalization(Wx_plus_b_conv3,128)\n",
    "            conv3_output=tf.nn.leaky_relu(batchnorm_conv3,alpha=0.3,name=\"relu3\")  \n",
    "\n",
    "        # layer cnn4\n",
    "        with tf.variable_scope('conv4') as scope: \n",
    "            W_conv4 = tf.get_variable('W_conv4', shape=[3,3,128,256])    \n",
    "            Wx_conv4 = tf.nn.conv2d(conv3_output, filter=W_conv4,strides=[1, 2, 2, 1], padding='SAME')  \n",
    "            b_conv4= tf.get_variable('b_conv4', shape=[256])\n",
    "            Wx_plus_b_conv4 = tf.nn.bias_add(Wx_conv4, b_conv4,name=\"Wx_plus_b4\")  \n",
    "            batchnorm_conv4 = batch_normalization(Wx_plus_b_conv4,256)\n",
    "            conv4_output=tf.nn.leaky_relu(batchnorm_conv4,alpha=0.3,name=\"relu4\")  \n",
    "\n",
    "        # layer cnn5\n",
    "        with tf.variable_scope('conv5') as scope: \n",
    "            W_conv5 = tf.get_variable('W_conv5', shape=[3,3,256,512])    \n",
    "            Wx_conv5 = tf.nn.conv2d(conv4_output, filter=W_conv5,strides=[1, 2, 2, 1], padding='SAME')  \n",
    "            b_conv5= tf.get_variable('b_conv5', shape=[512])\n",
    "            Wx_plus_b_conv5 = tf.nn.bias_add(Wx_conv5, b_conv5,name=\"Wx_plus_b5\")  \n",
    "            batchnorm_conv5 = batch_normalization(Wx_plus_b_conv5,512)\n",
    "            conv5_output=tf.nn.leaky_relu(batchnorm_conv5,alpha=0.3,name=\"relu5\")  \n",
    "\n",
    "        # global average pooling\n",
    "        with tf.variable_scope('avg_pool') as scope: \n",
    "            average_pool=tf.nn.avg_pool(conv5_output,ksize=[1,4,4,1],strides=[1,4,4,1],padding=\"SAME\")\n",
    "\n",
    "        # 50% dropout\n",
    "        with tf.variable_scope(\"dropout1\") as scope: \n",
    "            drop1_output=tf.nn.dropout(average_pool, pkeep)\n",
    "\n",
    "        # 1st fc layer\n",
    "        with tf.variable_scope(\"fc1\") as scope: \n",
    "            pool1flat = tf.reshape(drop1_output, shape=[-1,3* 3 * 512])\n",
    "            W_fc1 = tf.get_variable('W_fc1', shape=[3* 3 * 512, 1024])\n",
    "            b_fc1 = tf.get_variable('b_fc1', shape=[1024])\n",
    "            fc1_output = tf.nn.leaky_relu(tf.add(tf.matmul(pool1flat, W_fc1), b_fc1),alpha=0.3,name=\"fc1\")\n",
    "\n",
    "        # 50% dropout\n",
    "        with tf.variable_scope(\"dropout2\") as scope: \n",
    "            drop2_output=tf.nn.dropout(fc1_output, pkeep)\n",
    "\n",
    "        # 2nd fc layer\n",
    "        with tf.variable_scope(\"fc2\") as scope: \n",
    "            W_fc2 = tf.get_variable('W_fc2', shape=[1024, 2])\n",
    "            b_fc2 = tf.get_variable('b_fc2', shape=[2])\n",
    "            logits = tf.nn.relu(tf.add(tf.matmul(drop2_output, W_fc2), b_fc2),name='logits')\n",
    "\n",
    "    probs= tf.nn.softmax(logits)\n",
    "    ## Return the probability of the image [True, False]\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fab90db6-f384-4250-801e-7fff42e0fbd4"
    }
   },
   "source": [
    "## Part2. Training G and D concurrently  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "354c68cb-fdb0-4f19-8483-cd8c40587d4f"
    }
   },
   "source": [
    "(1) Generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbpresent": {
     "id": "9ac0d735-0ec4-4635-a6e8-7c21c7741907"
    }
   },
   "outputs": [],
   "source": [
    "def image_space_distance(x,g_x):\n",
    "    return tf.reduce_sum(tf.squared_difference(x,g_x),axis=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbpresent": {
     "id": "223257a2-1704-469b-b835-00349a50e1ce"
    }
   },
   "outputs": [],
   "source": [
    "def feature_space_distance(x,g_x):\n",
    "    c_x = Comparator_features(x)\n",
    "    c_g_x = Comparator_features(g_x)\n",
    "    dist1=tf.reduce_sum(tf.squared_difference(c_x[0],c_g_x[0]),axis=[0,1,2,3])\n",
    "    dist2=tf.reduce_sum(tf.squared_difference(c_x[1],c_g_x[1]),axis=[0,1,2,3])\n",
    "    dist3=tf.reduce_sum(tf.squared_difference(c_x[2],c_g_x[2]),axis=[0,1,2,3])\n",
    "    return dist1+dist2+dist3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbpresent": {
     "id": "4df8f40e-33ae-4c69-9022-f9749dfe5ac3"
    }
   },
   "outputs": [],
   "source": [
    "def Adversarial_loss(g_x):\n",
    "    with tf.variable_scope(\"g_x_probs\") as scope: \n",
    "        D_g_x=Discriminator_probs(g_x,0.5)\n",
    "    log_loss= tf.log(D_g_x[:,0])\n",
    "    adv_loss= -tf.reduce_sum(log_loss,axis=0)\n",
    "    return adv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbpresent": {
     "id": "096b346e-c4d0-438d-bb0c-05ada6ec91a7"
    }
   },
   "outputs": [],
   "source": [
    "def G_loss(x,g_x):\n",
    "    img_loss=image_space_distance(x,g_x)\n",
    "    feat_loss=feature_space_distance(x,g_x)\n",
    "    adv_loss=Adversarial_loss(g_x)\n",
    "    return (img_loss*5e-6)+(feat_loss*1e-7)+adv_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1a575a8a-b807-437a-b32b-acfddea99a2f"
    }
   },
   "source": [
    "(2) Discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbpresent": {
     "id": "e20dd02b-7602-4759-b97b-2556c86e6068"
    }
   },
   "outputs": [],
   "source": [
    "def D_loss(x,g_x):\n",
    "    with tf.variable_scope(\"x_probs\") as scope: \n",
    "        D_x = Discriminator_probs(x,0.5)\n",
    "    with tf.variable_scope(\"Gx_probs\") as scope: \n",
    "        D_g_x = Discriminator_probs(g_x,0.5)\n",
    "    x_loss = -tf.reduce_sum(tf.log(D_x[:,0]),axis=0)\n",
    "    g_x_loss = -tf.reduce_sum(tf.log(D_x[:,1]),axis=0)\n",
    "    return x_loss+g_x_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Take images into grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Note: The following 3 functions are referred from https://github.com/InFoCusp/tf_cnnvis/blob/master/tf_cnnvis/utils.py\n",
    "\n",
    "# This module is to form images into grid.\n",
    "\n",
    "def convert_into_grid(Xs, ubound=255.0, padding=1):\n",
    "    \"\"\"\n",
    "    Convert 4-D numpy array into a grid image\n",
    "    :param Xs: \n",
    "        A numpy array of images to make grid out of it\n",
    "    :type Xs: 4-D numpy array (first axis contations an image)\n",
    "    :param ubound: \n",
    "        upperbound for a image pixel value\n",
    "    :type ubound: float (Default = 255.0)\n",
    "    :param padding: \n",
    "        padding size between grid cells\n",
    "    :type padding: int (Default = 1)\n",
    "    :return: \n",
    "        A grid of input images \n",
    "    :rtype: 3-D numpy array\n",
    "    \"\"\"\n",
    "    (N, H, W, C) = Xs.shape\n",
    "    grid_size = int(ceil(sqrt(N)))\n",
    "    grid_height = H * grid_size + padding * (grid_size - 1)\n",
    "    grid_width = W * grid_size + padding * (grid_size - 1)\n",
    "    grid = np.zeros((grid_height, grid_width, C))\n",
    "    next_idx = 0\n",
    "    y0, y1 = 0, H\n",
    "    for y in range(grid_size):\n",
    "        x0, x1 = 0, W\n",
    "        for x in range(grid_size):\n",
    "            if next_idx < N:\n",
    "                grid[y0:y1, x0:x1] = Xs[next_idx]\n",
    "                next_idx += 1\n",
    "            x0 += W + padding\n",
    "            x1 += W + padding\n",
    "        y0 += H + padding\n",
    "        y1 += H + padding\n",
    "    return grid.astype('float32')\n",
    "\n",
    "def images_to_grid(images):\n",
    "    \"\"\"\n",
    "    Convert a list of arrays of images into a list of grid of images\n",
    "    :param images: \n",
    "        a list of 4-D numpy arrays(each containing images)\n",
    "    :type images: list\n",
    "    :return: \n",
    "        a list of grids which are grid representation of input images\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    grid_images = []\n",
    "    # if 'images' is not empty convert\n",
    "    # list of images into grid of images\n",
    "    if len(images) > 0:\n",
    "        N = len(images)\n",
    "        H, W, C = images[0][0].shape\n",
    "        for j in range(len(images[0])):\n",
    "            tmp = np.zeros((N, H, W, C))\n",
    "            for i in range(N):\n",
    "                tmp[i] = images[i][j]\n",
    "            grid_images.append(np.expand_dims(convert_into_grid(tmp), axis = 0))\n",
    "    return grid_images\n",
    "\n",
    "def write_deconv(images,layer,path_outdir,filename):\n",
    "    grid_images = images_to_grid(images)\n",
    "\n",
    "    # write into disk\n",
    "    path_out = os.path.join(path_outdir, layer.lower().replace(\"/\", \"_\"))\n",
    "\n",
    "    for i in range(len(grid_images)):\n",
    "        image_data=grid_images[i]\n",
    "        resized_images=tf.image.resize_nearest_neighbor(image_data,size=[299,299])\n",
    "        with tf.Session() as sess:\n",
    "            resized_image_data=resized_images.eval()\n",
    "        grid_image_path = os.path.join(path_out)\n",
    "        if os.path.isdir(grid_image_path):\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(grid_image_path)\n",
    "        if image_data.shape[-1] == 1:\n",
    "            imsave(os.path.join(grid_image_path,filename+\".png\"),resized_image_data[0,:,:,:], format = \"png\")\n",
    "        else:\n",
    "            imsave(os.path.join(grid_image_path,filename+\".png\"), resized_image_data[0], format = \"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4843ce5b-104f-4677-b935-4e52b814f849"
    }
   },
   "source": [
    "### 2. Preparing the train and val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_image,train_logits,val_image,val_logits = generate_dataset(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(batch_size,epoch,iteration,val_ratio,image_path):   \n",
    "    start_time = time.time()\n",
    "    with tf.Graph().as_default():\n",
    "        val_size = int(batch_size*iteration*val_ratio)\n",
    "        with tf.name_scope(\"input\") as scope:\n",
    "            image_train = tf.placeholder(tf.float32, [batch_size,299,299,3], name='image')\n",
    "            feature_train = tf.placeholder(tf.float32, [batch_size,1008], name='feature')\n",
    "            image_val=tf.placeholder(tf.float32, [val_size,299,299,3], name='image')\n",
    "            feature_val = tf.placeholder(tf.float32, [val_size,1008], name='feature')\n",
    "            \n",
    "        with tf.variable_scope(\"train_fake_image\") as scope: \n",
    "            train_g_image=Generator_image(feature_train,batch_size)\n",
    "            \n",
    "        with tf.variable_scope(\"val_fake_image\") as scope: \n",
    "            val_g_image=Generator_image(feature_val,val_size)\n",
    "\n",
    "        with tf.variable_scope(\"train_G_loss\") as scope: \n",
    "            train_g_loss=G_loss(image_train,train_g_image)\n",
    "            \n",
    "        with tf.variable_scope(\"val_G_loss\") as scope: \n",
    "            val_g_loss=G_loss(image_val,val_g_image)\n",
    "\n",
    "        with tf.variable_scope(\"train_D_loss\") as scope: \n",
    "            train_d_loss=D_loss(image_train,train_g_image)\n",
    "            \n",
    "        with tf.variable_scope(\"val_D_loss\") as scope: \n",
    "            val_d_loss=D_loss(image_val,val_g_image) \n",
    "\n",
    "        with tf.variable_scope(\"Optimizer\") as scope: \n",
    "            opt_G = tf.train.AdamOptimizer(2e-4)\n",
    "            opt_D = tf.train.AdamOptimizer(2e-4)\n",
    "            train_step_G = opt_G.minimize(train_g_loss)\n",
    "            train_step_D = opt_D.minimize(train_d_loss)\n",
    "            \n",
    "        with tf.name_scope('summaries'):\n",
    "            # create summary for loss \n",
    "            tf.summary.scalar('train_g_loss', train_g_loss) \n",
    "            tf.summary.scalar('train_d_loss', train_d_loss) \n",
    "            # create summary for input image\n",
    "            for i in range(epoch):\n",
    "                tf.summary.image('train_output', tf.reshape(train_g_image, [-1, 299, 299, 3]))\n",
    "                \n",
    "            summary_op = tf.summary.merge_all()\n",
    "            \n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "            dir_name=\"./log\"\n",
    "            summary_writer = tf.summary.FileWriter(dir_name, sess.graph)\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for i in range(epoch):\n",
    "                epoch_index = np.random.choice(len(image_path),batch_size*iteration)\n",
    "                epoch_path = [image_path[i] for i in epoch_index]\n",
    "                train_image,train_feature,val_image,val_feature = generate_dataset(epoch_path,val_ratio)\n",
    "                for j in range(iteration):\n",
    "                    batch_index = np.random.choice(train_image.shape[0],batch_size)\n",
    "                    image_batch = train_image[batch_index,:,:,:]\n",
    "                    feature_batch = train_feature[batch_index,:]\n",
    "\n",
    "                    # now run\n",
    "                    _ ,summary = sess.run((train_step_G, summary_op),feed_dict={image_train: image_batch, feature_train: feature_batch})\n",
    "                    \n",
    "                    _ ,summary= sess.run((train_step_D, summary_op),feed_dict={image_train: image_batch, feature_train: feature_batch})\n",
    "                    # write the summary output to file\n",
    "                    if j%5 == 0:\n",
    "                        val_G_loss = sess.run((val_g_loss), feed_dict={image_val: val_image, feature_val: val_feature})\n",
    "                        val_D_loss = sess.run((val_d_loss), feed_dict={image_val: val_image, feature_val: val_feature})\n",
    "                        print(\"val_G_loss:\",val_G_loss)\n",
    "                        print(\"val_D_loss:\",val_D_loss)\n",
    "                        print(\"iteration:\"+str(j)+\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "               \n",
    "                print(\"epoch:\"+str(i)+\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "                #if i%(epoch/10)==0:\n",
    "                val_fake_image = sess.run((val_g_image), feed_dict={image_val: val_image, feature_val: val_feature})\n",
    "                real=[i.reshape(-1,299,299,3) for i in val_image]\n",
    "                fake=[i.reshape(-1,299,299,3) for i in val_fake_image]\n",
    "                write_deconv(fake,\"logits_fake\",\"./saveimage\",\"fake_image_epoch\"+str(i))\n",
    "                write_deconv(real,\"logits_image\",\"./saveimage\",\"real_image_epoch\"+str(i))\n",
    "            \n",
    "            save_path = saver.save(sess, \"./log/save_net.ckpt\")\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "nbpresent": {
     "id": "2061f710-1f6b-4ef8-9f08-477ce74f621d"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image:0--- 1.022810935974121 seconds ---\n",
      "val_G_loss: 14.7594\n",
      "val_D_loss: 13.5615\n",
      "iteration:0--- 39.78139853477478 seconds ---\n",
      "epoch:0--- 41.63439965248108 seconds ---\n",
      "loading image:0--- 1.0459890365600586 seconds ---\n",
      "val_G_loss: 13.8537\n",
      "val_D_loss: 13.1813\n",
      "iteration:0--- 66.99652814865112 seconds ---\n",
      "epoch:1--- 68.8501570224762 seconds ---\n"
     ]
    }
   ],
   "source": [
    "hey=training(20,2,2,0.2,image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real=[i.reshape(-1,299,299,3) for i in hey[0]]\n",
    "fake=[i.reshape(-1,299,299,3) for i in hey[1]]\n",
    "\n",
    "write_deconv(real,\"logits_image\",\"./saveimage\",\"real_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_deconv(fake,\"logits_fake1\",\"./saveimage\",\"fake_image1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "9ec87186-ee8a-45dc-8853-a9ddb41f514a"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
