{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"green\"> Inception-v3 <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import transfer_learning_v3 # This module is from homework4 and we just made several changes to the return values of _create_model() \n",
    "import pandas as pd\n",
    "from scipy.misc import imsave\n",
    "from scipy.stats import rankdata\n",
    "import time\n",
    "import fnmatch\n",
    "from PIL import Image\n",
    "from math import ceil, sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method1:  Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the tensor holder from the pretrained inception-v3 model\n",
    "graph, bottleneck, resized_input, softmax, conv,conv1,conv2,pool,conv3,conv4,pool1,conv_W,conv1_W,conv2_W,conv3_W,conv4_W = transfer_learning_v3.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the image paths of our dataset\n",
    "images = ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.tiff']\n",
    "image_list = []\n",
    "for root,dirnames, filenames in os.walk(\"F:/University/coursework/2017 Fall/Advanced Machine Learning/project/data/patch_images/train\"):\n",
    "    for extension in images:\n",
    "        for filename in fnmatch.filter(filenames, extension):\n",
    "            image_list.append(os.path.join(root, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a batch sample of images\n",
    "batch_size=50\n",
    "np.random.seed(1)\n",
    "image_paths=[image_list[i] for i in np.random.choice(range(len(image_list)),batch_size,replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.2794044017791748 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Get the pixel data we need \n",
    "image_data=[]\n",
    "resized_image_output=[]\n",
    "conv_output=[]\n",
    "conv1_output=[]\n",
    "conv2_output=[]\n",
    "pool_output=[]\n",
    "conv3_output=[]\n",
    "conv4_output=[]\n",
    "pool1_output=[]\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(len(image_paths)):\n",
    "    image_path = image_paths[i]\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_data=f.read()\n",
    "    with graph.as_default():\n",
    "        tensor_name_input_jpeg=\"DecodeJpeg/contents:0\"\n",
    "        tensor_name_input_image=\"DecodeJpeg:0\"\n",
    "        tensor_name_resized_image=\"Mul:0\"\n",
    "        tensor_name_softmax=\"softmax:0\"\n",
    "        tensor_name_transfer_layer = \"pool_3/_reshape:0\"\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        resized_image_output.append(session.run(resized_input,feed_dict={tensor_name_input_jpeg:image_data}))\n",
    "        conv_output.append(session.run(conv,feed_dict={tensor_name_input_jpeg:image_data}))\n",
    "        conv1_output.append(session.run(conv1,feed_dict={tensor_name_input_jpeg:image_data}))\n",
    "        conv2_output.append(session.run(conv2,feed_dict={tensor_name_input_jpeg:image_data}))\n",
    "        pool_output.append(session.run(pool,feed_dict={tensor_name_input_jpeg:image_data}))\n",
    "        conv3_output.append(session.run(conv3,feed_dict={tensor_name_input_jpeg:image_data}))\n",
    "        conv4_output.append(session.run(conv4,feed_dict={tensor_name_input_jpeg:image_data}))\n",
    "        pool1_output.append(session.run(pool1,feed_dict={tensor_name_input_jpeg:image_data}))\n",
    "        conv_W_output=session.run(conv_W,feed_dict={tensor_name_input_jpeg:image_data})\n",
    "        conv1_W_output=session.run(conv1_W,feed_dict={tensor_name_input_jpeg:image_data})\n",
    "        conv2_W_output=session.run(conv2_W,feed_dict={tensor_name_input_jpeg:image_data})\n",
    "        conv3_W_output=session.run(conv3_W,feed_dict={tensor_name_input_jpeg:image_data})\n",
    "        conv4_W_output=session.run(conv4_W,feed_dict={tensor_name_input_jpeg:image_data})\n",
    "    if i%50==0:\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the deconvolution network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define Unpooling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unpool Method1: The unpool_1 function is referred from https://github.com/kvfrans/feature-visualization/blob/master/main.py\n",
    "\n",
    "def unpool_1(value,shape):\n",
    "    \"\"\"N-dimensional version of the unpooling operation from\n",
    "    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
    "    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\n",
    "    :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\n",
    "    \"\"\"\n",
    "    sh = list(value.shape)\n",
    "    dim = len(sh[1:-1])\n",
    "    out = (tf.reshape(value, [-1] + sh[-dim:]))\n",
    "    for i in range(dim, 0, -1):\n",
    "        out = tf.concat([out, out],i)\n",
    "    out_size = [-1] + [(s*2) for s in sh[1:-1]] + [sh[-1]]\n",
    "    out = tf.reshape(out, out_size)\n",
    "    # To solve the problem that strides=[1,2,2,1] of the maxpooling layer losing one column and one row compared to the original channel\n",
    "    out1=tf.image.resize_nearest_neighbor(out,size=[shape,shape])\n",
    "    with tf.Session() as sess:\n",
    "        result=out1.eval()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unpool Method2: For each filter, find the location of its maximum and set other pixels as 0.\n",
    "\n",
    "## Return the location of the maximum of a given matrix.\n",
    "def argmax_coords(v):\n",
    "    indice_coords=[]\n",
    "    for i in range(0,v.shape[0]-1,2):\n",
    "        for j in range(0,v.shape[1]-1,2):\n",
    "            indice=v[i:(i+3),j:(j+3)]\n",
    "            argmax=np.argmax(indice)\n",
    "            indice_coords.append([[x,y] for x in range(i,(i+3)) for y in range(j,(j+3))][argmax])\n",
    "    return indice_coords\n",
    "\n",
    "\n",
    "## Keep the maximum of each filter and set other pixel as 0.\n",
    "def unpool_2(value,pools):\n",
    "    b=[]\n",
    "    with tf.Session() as sess:\n",
    "        pool1=tf.reshape(pools,[1,-1,64]).eval()\n",
    "    for i in range(value.shape[3]):\n",
    "        coords=np.asarray(argmax_coords(value[0,:,:,i]))\n",
    "        unpools=np.zeros([147,147])\n",
    "        for j in range(len(coords)):\n",
    "            unpools[coords[j,0],coords[j,1]]=pool1[0,:,i][j]\n",
    "        b.append(unpools)\n",
    "    c=np.stack((b),axis=2)\n",
    "    c=tf.reshape(c,[-1,147,147,64])\n",
    "    c=tf.cast(c, tf.float32)\n",
    "    with tf.Session() as sess:\n",
    "        d=c.eval()\n",
    "    return d "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define Deconvolutionl Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" For the deconvolution network construction, we are inspired by the article\n",
    "  http://kvfrans.com/visualizing-features-from-a-convolutional-neural-network/\n",
    "    The author apply the deconvolution network to a simple 2-cnn layer. Inspired by this article, we construct the deconvolution network \n",
    "    for the cnn layers and pooling layers of inception-v3 model.\n",
    "\"\"\"\n",
    "\n",
    "featuresReLu1 = tf.placeholder(\"float\",[None,71,71,192])\n",
    "featuresReLu2 = tf.placeholder(\"float\",[None,147,147,64])\n",
    "unReLu_4 = tf.nn.relu(featuresReLu1)\n",
    "unBias_4 = unReLu_4\n",
    "unConv_4 = tf.nn.conv2d_transpose(unBias_4,conv4_W_output, output_shape=[1,73,73,80] , strides=[1,1,1,1], padding=\"VALID\")\n",
    "unReLu_3 = tf.nn.relu(unConv_4)\n",
    "unBias_3 = unReLu_3\n",
    "unConv_3 = tf.nn.conv2d_transpose(unBias_3,conv3_W_output, output_shape=[1,73,73,64] , strides=[1,1,1,1], padding=\"VALID\")\n",
    "\n",
    "unReLu_2 = tf.nn.relu(featuresReLu2)\n",
    "unBias_2 = unReLu_2\n",
    "unConv_2 = tf.nn.conv2d_transpose(unBias_2,conv2_W_output, output_shape=[1,147,147,32] , strides=[1,1,1,1], padding=\"SAME\")\n",
    "unReLu_1 = tf.nn.relu(unConv_2)\n",
    "unBias_1 = unReLu_1\n",
    "unConv_1 = tf.nn.conv2d_transpose(unBias_1,conv1_W_output, output_shape=[1,149,149,32] , strides=[1,1,1,1], padding=\"VALID\")\n",
    "unReLu_0 = tf.nn.relu(unConv_1)\n",
    "unBias_0 = unReLu_0\n",
    "unConv_0 = tf.nn.conv2d_transpose(unBias_0,conv_W_output, output_shape=[1,299,299,3] , strides=[1,2,2,1], padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.3 Define the optimization function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) argmax(pixel_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) agrmax(pixel_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) optimizer_square_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizer_square_distance(im,k):\n",
    "    distance=[np.sum((resized_image_output[i][0,:,:,:]-im[i])**2) for i in range(len(resized_image_output))]\n",
    "    argmins=np.array(distance).reshape(-1).argsort()[:k]\n",
    "    return argmins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4)optimizer_rank_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizer_rank_distance(im):\n",
    "    distance=[np.sum((rankdata(resized_image_output[i][0,:,:,:])-rankdata(im[i]))**2) for i in range(len(resized_image_output))]\n",
    "    argmins=np.array(distance).reshape(-1).argsort()[:k]\n",
    "    return argmins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Take images into grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Note: The following 3 functions are referred from https://github.com/InFoCusp/tf_cnnvis/blob/master/tf_cnnvis/utils.py\n",
    "\n",
    "# This module is to form images into grid.\n",
    "\n",
    "def convert_into_grid(Xs, ubound=255.0, padding=1):\n",
    "    \"\"\"\n",
    "    Convert 4-D numpy array into a grid image\n",
    "    :param Xs: \n",
    "        A numpy array of images to make grid out of it\n",
    "    :type Xs: 4-D numpy array (first axis contations an image)\n",
    "    :param ubound: \n",
    "        upperbound for a image pixel value\n",
    "    :type ubound: float (Default = 255.0)\n",
    "    :param padding: \n",
    "        padding size between grid cells\n",
    "    :type padding: int (Default = 1)\n",
    "    :return: \n",
    "        A grid of input images \n",
    "    :rtype: 3-D numpy array\n",
    "    \"\"\"\n",
    "    (N, H, W, C) = Xs.shape\n",
    "    grid_size = int(ceil(sqrt(N)))\n",
    "    grid_height = H * grid_size + padding * (grid_size - 1)\n",
    "    grid_width = W * grid_size + padding * (grid_size - 1)\n",
    "    grid = np.zeros((grid_height, grid_width, C))\n",
    "    next_idx = 0\n",
    "    y0, y1 = 0, H\n",
    "    for y in range(grid_size):\n",
    "        x0, x1 = 0, W\n",
    "        for x in range(grid_size):\n",
    "            if next_idx < N:\n",
    "                grid[y0:y1, x0:x1] = Xs[next_idx]\n",
    "                next_idx += 1\n",
    "            x0 += W + padding\n",
    "            x1 += W + padding\n",
    "        y0 += H + padding\n",
    "        y1 += H + padding\n",
    "    return grid.astype('float32')\n",
    "\n",
    "def images_to_grid(images):\n",
    "    \"\"\"\n",
    "    Convert a list of arrays of images into a list of grid of images\n",
    "    :param images: \n",
    "        a list of 4-D numpy arrays(each containing images)\n",
    "    :type images: list\n",
    "    :return: \n",
    "        a list of grids which are grid representation of input images\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    grid_images = []\n",
    "    # if 'images' is not empty convert\n",
    "    # list of images into grid of images\n",
    "    if len(images) > 0:\n",
    "        N = len(images)\n",
    "        H, W, C = images[0][0].shape\n",
    "        for j in range(len(images[0])):\n",
    "            tmp = np.zeros((N, H, W, C))\n",
    "            for i in range(N):\n",
    "                tmp[i] = images[i][j]\n",
    "            grid_images.append(np.expand_dims(convert_into_grid(tmp), axis = 0))\n",
    "    return grid_images\n",
    "\n",
    "def write_deconv(images,layer,path_outdir,filename):\n",
    "    grid_images = images_to_grid(images)\n",
    "\n",
    "    # write into disk\n",
    "    path_out = os.path.join(path_outdir, layer.lower().replace(\"/\", \"_\"))\n",
    "\n",
    "    for i in range(len(grid_images)):\n",
    "        image_data=grid_images[i]\n",
    "        resized_images=tf.image.resize_nearest_neighbor(image_data,size=[299,299])\n",
    "        with tf.Session() as sess:\n",
    "            resized_image_data=resized_images.eval()\n",
    "        grid_image_path = os.path.join(path_out)\n",
    "        os.mkdir(grid_image_path)\n",
    "        if image_data.shape[-1] == 1:\n",
    "            imsave(os.path.join(grid_image_path,filename+\".png\"),resized_image_data[0,:,:,:], format = \"png\")\n",
    "        else:\n",
    "            imsave(os.path.join(grid_image_path,filename+\".png\"), resized_image_data[0], format = \"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display the images that  activate each feature maps most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each layer, this module displays the top k=9 images that activates a certain feature map most and we take them into grid.\n",
    "# The number of best gridded images is equal to the number of feature maps of this layer.\n",
    "# The best images are chosen from the batch sample of iamges, which is defined earlier.\n",
    "# This module is inspired by https://github.com/kvfrans/feature-visualization/blob/master/main.py\n",
    "\n",
    "class deconv_feature_map_layers:\n",
    "    def __init__(self):\n",
    "        self.method=\"argmax_var\"\n",
    "        self.k=4   ## Choose the top k images that activate the feature map most\n",
    "        \n",
    "    \n",
    "    def deconv_conv(self,value):\n",
    "        start_time = time.time()\n",
    "        # define types of variables\n",
    "        bests=[]\n",
    "        with tf.Session() as sess:\n",
    "            for j in range(value[0].shape[-1]):\n",
    "                imagedata=[]\n",
    "                totals=[]\n",
    "                var=[]\n",
    "                unConvs=[]\n",
    "                for i in range(len(value)):\n",
    "                    # display features\n",
    "                    isolated = value[i].copy()\n",
    "                    isolated[:,:,:,:j] = 0\n",
    "                    isolated[:,:,:,j+1:] = 0\n",
    "                    unConv=unConv_0.eval(feed_dict={unReLu_0: isolated})\n",
    "                    unConvs.append(unConv)\n",
    "                    imagedata.append(unConv[0,:,:,:])\n",
    "                    totals.append(np.sum(isolated,axis=(1,2,3)))\n",
    "                    var.append(np.var(isolated,axis=(1,2,3)))\n",
    "                    pixel_sum=[np.sum(i) for i in imagedata]\n",
    "                # This was inspired by the article https://github.com/kvfrans/feature-visualization/blob/master/main.py\n",
    "                ## Choose the best image\n",
    "                if self.method==\"argmax_sum\":\n",
    "                    best=(-np.array(totals)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                # This was inspired by the article https://www.sciencedirect.com/science/article/pii/S1877050917323840\n",
    "                elif self.method==\"argmax_var\":\n",
    "                    best=(-np.array(var)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_square_distance\":\n",
    "                    best=optimizer_square_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_rank_distance\":\n",
    "                    best=optimizer_rank_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                best_feature_maps=[unConvs[i] for i in best]\n",
    "                best_images=[resized_image_output[i] for i in best]\n",
    "                write_deconv(best_feature_maps,\"conv_\"+\"feature\"+str(j),\"./deconv/feature_maps/conv\",\"top\"+str(self.k)+\"feature_maps\")\n",
    "                write_deconv(best_images,\"conv_\"+\"feature\"+str(j),\"./deconv/images/conv\",\"top\"+str(self.k)+\"images\")\n",
    "                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    \n",
    "    def deconv_conv1(self,value):\n",
    "        start_time = time.time()\n",
    "        bests=[]\n",
    "        with tf.Session() as sess:\n",
    "            for j in range(value[0].shape[-1]):\n",
    "                # define types of variables\n",
    "                imagedata=[]\n",
    "                totals=[]\n",
    "                var=[]\n",
    "                unConvs=[]\n",
    "                for i in range(len(value)):\n",
    "                    # display features\n",
    "                    isolated = value[i].copy()\n",
    "                    isolated[:,:,:,:j] = 0\n",
    "                    isolated[:,:,:,j+1:] = 0\n",
    "                    unConv=unConv_0.eval(feed_dict={unReLu_1: isolated})\n",
    "                    unConvs.append(unConv)\n",
    "                    imagedata.append(unConv[0,:,:,:])\n",
    "                    totals.append(np.sum(isolated,axis=(1,2,3)))\n",
    "                    var.append(np.var(isolated,axis=(1,2,3)))\n",
    "                    pixel_sum=[np.sum(i) for i in imagedata]\n",
    "                ## Choose the best image\n",
    "                if self.method==\"argmax_sum\":\n",
    "                    best=(-np.array(totals)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmax_var\":\n",
    "                    best=(-np.array(var)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_square_distance\":\n",
    "                    best=optimizer_square_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_rank_distance\":\n",
    "                    best=optimizer_rank_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                best_feature_maps=[unConvs[i] for i in best]\n",
    "                best_images=[resized_image_output[i] for i in best]\n",
    "                write_deconv(best_feature_maps,\"conv1_\"+\"feature\"+str(j),\"./deconv/feature_maps/conv1\",\"top\"+str(self.k)+\"feature_maps\")\n",
    "                write_deconv(best_images,\"conv1_\"+\"feature\"+str(j),\"./deconv/images/conv1\",\"top\"+str(self.k)+\"images\")\n",
    "                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "   \n",
    "    def deconv_conv2(self,value):\n",
    "        start_time = time.time()\n",
    "        bests=[]\n",
    "        with tf.Session() as sess:\n",
    "            for j in range(value[0].shape[-1]):\n",
    "                imagedata=[]\n",
    "                totals=[]\n",
    "                var=[]\n",
    "                unConvs=[]\n",
    "                for i in range(len(value)):\n",
    "                    # display features\n",
    "                    isolated = value[i].copy()\n",
    "                    isolated[:,:,:,:j] = 0\n",
    "                    isolated[:,:,:,j+1:] = 0\n",
    "                    unConv=unConv_0.eval(feed_dict={unReLu_2: isolated})\n",
    "                    unConvs.append(unConv)\n",
    "                    imagedata.append(unConv[0,:,:,:])\n",
    "                    totals.append(np.sum(isolated,axis=(1,2,3)))\n",
    "                    var.append(np.var(isolated,axis=(1,2,3)))\n",
    "                    pixel_sum=[np.sum(i) for i in imagedata]\n",
    "                ## Choose the best image\n",
    "                if self.method==\"argmax_sum\":\n",
    "                    best=(-np.array(totals)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmax_var\":\n",
    "                    best=(-np.array(var)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_square_distance\":\n",
    "                    best=optimizer_square_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_rank_distance\":\n",
    "                    best=optimizer_rank_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                best_feature_maps=[unConvs[i] for i in best]\n",
    "                best_images=[resized_image_output[i] for i in best]\n",
    "                write_deconv(best_feature_maps,\"conv2_\"+\"feature\"+str(j),\"./deconv/feature_maps/conv2\",\"top\"+str(self.k)+\"feature_maps\")\n",
    "                write_deconv(best_images,\"conv2_\"+\"feature\"+str(j),\"./deconv/images/conv2\",\"top\"+str(self.k)+\"images\")\n",
    "                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    \n",
    "    def deconv_pool(self,v):\n",
    "        start_time = time.time()\n",
    "        with tf.Session() as sess:\n",
    "            bests=[]\n",
    "            for j in range(v[0].shape[-1]):\n",
    "                imagedata=[]\n",
    "                totals=[]\n",
    "                var=[]\n",
    "                unConvs=[]\n",
    "                for i in range(len(v)):\n",
    "                    # display features\n",
    "                    isolated=v[i].copy()\n",
    "                    isolated[:,:,:,:j] = 0\n",
    "                    isolated[:,:,:,j+1:] = 0\n",
    "                    value=unpool_1(isolated,147)\n",
    "                    unConv=unConv_0.eval(feed_dict={unReLu_2: value})\n",
    "                    unConvs.append(unConv)\n",
    "                    imagedata.append(unConv[0,:,:,:])\n",
    "                    totals.append(np.sum(isolated,axis=(1,2,3)))\n",
    "                    var.append(np.var(isolated,axis=(1,2,3)))\n",
    "                    pixel_sum=[np.sum(i) for i in imagedata]\n",
    "                ## Choose the best image\n",
    "                if self.method==\"argmax_sum\":\n",
    "                    best=(-np.array(totals)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmax_var\":\n",
    "                    best=(-np.array(var)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_square_distance\":\n",
    "                    best=optimizer_square_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_rank_distance\":\n",
    "                    best=optimizer_rank_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                best_feature_maps=[unConvs[i] for i in best]\n",
    "                best_images=[resized_image_output[i] for i in best]\n",
    "                write_deconv(best_feature_maps,\"pool_\"+\"feature\"+str(j),\"./deconv/feature_maps/pool\",\"top\"+str(self.k)+\"feature_maps\")\n",
    "                write_deconv(best_images,\"pool_\"+\"feature\"+str(j),\"./deconv/images/pool\",\"top\"+str(self.k)+\"images\")\n",
    "                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "                \n",
    "      \n",
    "    def deconv_conv3(self,v):\n",
    "        start_time = time.time()\n",
    "        with tf.Session() as sess:\n",
    "            bests=[]\n",
    "            for j in range(v[0].shape[-1]):\n",
    "                imagedata=[]\n",
    "                totals=[]\n",
    "                var=[]\n",
    "                unConvs=[]\n",
    "                for i in range(len(v)):\n",
    "                    # display features\n",
    "                    isolated = v[i].copy()\n",
    "                    isolated[:,:,:,:j] = 0\n",
    "                    isolated[:,:,:,j+1:] = 0\n",
    "                    unconv3=unConv_3.eval(feed_dict={unReLu_3: isolated})\n",
    "                    unpool=unpool_1(unconv3,147)\n",
    "                    unConv=unConv_0.eval(feed_dict={unReLu_2: unpool})\n",
    "                    unConvs.append(unConv)\n",
    "                    imagedata.append(unConv[0,:,:,:])\n",
    "                    totals.append(np.sum(isolated,axis=(1,2,3)))\n",
    "                    var.append(np.var(isolated,axis=(1,2,3)))\n",
    "                    pixel_sum=[np.sum(i) for i in imagedata]\n",
    "                ## Choose the best image\n",
    "                if self.method==\"argmax_sum\":\n",
    "                    best=(-np.array(totals)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmax_var\":\n",
    "                    best=(-np.array(var)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_square_distance\":\n",
    "                    best=optimizer_square_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_rank_distance\":\n",
    "                    best=optimizer_rank_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                best_feature_maps=[unConvs[i] for i in best]\n",
    "                best_images=[resized_image_output[i] for i in best]\n",
    "                write_deconv(best_feature_maps,\"conv3_\"+\"feature\"+str(j),\"./deconv/feature_maps/conv3\",\"top\"+str(self.k)+\"feature_maps\")\n",
    "                write_deconv(best_images,\"conv3_\"+\"feature\"+str(j),\"./deconv/images/conv3\",\"top\"+str(self.k)+\"images\")\n",
    "                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    def deconv_conv4(self,v):\n",
    "        start_time = time.time()\n",
    "        with tf.Session() as sess:\n",
    "            bests=[]\n",
    "            for j in chosen:\n",
    "                imagedata=[]\n",
    "                totals=[]\n",
    "                var=[]\n",
    "                unConvs=[]\n",
    "                for i in range(len(v)):\n",
    "                    # display features\n",
    "                    isolated = v[i].copy()\n",
    "                    isolated[:,:,:,:j] = 0\n",
    "                    isolated[:,:,:,j+1:] = 0\n",
    "                    unconv3=unConv_3.eval(feed_dict={unReLu_4: isolated})\n",
    "                    unpool=unpool_1(unconv3,147)\n",
    "                    unConv=unConv_0.eval(feed_dict={unReLu_2: unpool})\n",
    "                    unConvs.append(unConv)\n",
    "                    imagedata.append(unConv[0,:,:,:])\n",
    "                    totals.append(np.sum(isolated,axis=(1,2,3)))\n",
    "                    var.append(np.var(isolated,axis=(1,2,3)))\n",
    "                    pixel_sum=[np.sum(i) for i in imagedata]\n",
    "                ## Choose the best image\n",
    "                if self.method==\"argmax_sum\":\n",
    "                    best=(-np.array(totals)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmax_var\":\n",
    "                    best=(-np.array(var)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_square_distance\":\n",
    "                    best=optimizer_square_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_rank_distance\":\n",
    "                    best=optimizer_rank_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                best_feature_maps=[unConvs[i] for i in best]\n",
    "                best_images=[resized_image_output[i] for i in best]\n",
    "                write_deconv(best_feature_maps,\"conv4_\"+\"feature\"+str(j),\"./deconv/feature_maps/conv4\",\"top\"+str(self.k)+\"feature_maps\")\n",
    "                write_deconv(best_images,\"conv4_\"+\"feature\"+str(j),\"./deconv/images/conv4\",\"top\"+str(self.k)+\"images\")\n",
    "                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    \n",
    "    def deconv_pool1(self,v):\n",
    "        start_time = time.time()\n",
    "        with tf.Session() as sess:\n",
    "            bests=[]\n",
    "            for j in chosen:\n",
    "                imagedata=[]\n",
    "                totals=[]\n",
    "                var=[]\n",
    "                unConvs=[]\n",
    "                for i in range(len(v)):\n",
    "                    # display features\n",
    "                    isolated = v[i].copy()\n",
    "                    isolated[:,:,:,:j] = 0\n",
    "                    isolated[:,:,:,j+1:] = 0\n",
    "                    unpool1=unpool_1(isolated,71)\n",
    "                    unconv3=unConv_3.eval(feed_dict={unReLu_4: unpool1})\n",
    "                    unpool=unpool_1(unconv3,147)\n",
    "                    unConv=unConv_0.eval(feed_dict={unReLu_2: unpool})\n",
    "                    unConvs.append(unConv)\n",
    "                    imagedata.append(unConv[0,:,:,:])\n",
    "                    totals.append(np.sum(isolated,axis=(1,2,3)))\n",
    "                    var.append(np.var(isolated,axis=(1,2,3)))\n",
    "                    pixel_sum=[np.sum(i) for i in imagedata]\n",
    "                ## Choose the best image\n",
    "                if self.method==\"argmax_sum\":\n",
    "                    best=(-np.array(totals)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmax_var\":\n",
    "                    best=(-np.array(var)).reshape(-1).argsort()[:self.k]\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_square_distance\":\n",
    "                    best=optimizer_square_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                elif self.method==\"argmin_rank_distance\":\n",
    "                    best=optimizer_rank_distance(imagedata,self.k)\n",
    "                    bests.append(best)\n",
    "                    print(best)\n",
    "                    print(\"feature\"+str(j))\n",
    "                best_feature_maps=[unConvs[i] for i in best]\n",
    "                best_images=[resized_image_output[i] for i in best]\n",
    "                write_deconv(best_feature_maps,\"pool1_\"+\"feature\"+str(j),\"./deconv/feature_maps/pool1\",\"top\"+str(self.k)+\"feature_maps\")\n",
    "                write_deconv(best_images,\"pool1_\"+\"feature\"+str(j),\"./deconv/images/pool1\",\"top\"+str(self.k)+\"images\")\n",
    "                print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#some=deconv_feature_map_layers()\n",
    "#some.deconv_conv4(conv4_output) # get the 64 best images of conv2 layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
